namespace com.sleepycat.je.recovery;

class Checkpointer
{
  depend de.ovgu.cide.jakutil.*;
  depend com.sleepycat.je.utilint.Tracer;
  depend com.sleepycat.je.utilint.PropUtil;
  depend com.sleepycat.je.utilint.DbLsn;
  depend com.sleepycat.je.utilint.DaemonThread;
  depend com.sleepycat.je.tree.Tree;
  depend com.sleepycat.je.tree.SearchResult;
  depend com.sleepycat.je.tree.Node;
  depend com.sleepycat.je.tree.IN;
  depend com.sleepycat.je.tree.BIN;
  depend com.sleepycat.je.log.LogManager;
  depend com.sleepycat.je.dbi.MemoryBudget;
  depend com.sleepycat.je.dbi.INList;
  depend com.sleepycat.je.dbi.EnvironmentImpl;
  depend com.sleepycat.je.dbi.DbTree;
  depend com.sleepycat.je.dbi.DbConfigManager;
  depend com.sleepycat.je.dbi.DatabaseImpl;
  depend com.sleepycat.je.config.EnvironmentParams;
  depend com.sleepycat.je.cleaner.UtilizationProfile;
  depend com.sleepycat.je.cleaner.TrackedFileSummary;
  depend com.sleepycat.je.cleaner.Cleaner;
  depend com.sleepycat.je.DbInternal;
  depend com.sleepycat.je.DatabaseException;
  depend com.sleepycat.je.CheckpointConfig;
  depend java.util.logging.Level;
  depend java.util.TreeMap;
  depend java.util.SortedMap;
  depend java.util.Set;
  depend java.util.Map;
  depend java.util.Iterator;
  depend java.util.HashSet;
    private EnvironmentImpl envImpl;

    private LogManager logManager;

    private long checkpointId;

    private long logFileMax;

    private long lastCheckpointMillis;

    private long lastFirstActiveLsn;

    private long lastCheckpointEnd;

    private volatile int highestFlushLevel;

    public Checkpointer(EnvironmentImpl envImpl, long waitTime, String name) throws DatabaseException {
	this.hook538(envImpl, waitTime, name);
	this.envImpl = envImpl;
	this.hook539(envImpl);
	logFileMax = envImpl.getConfigManager().getLong(EnvironmentParams.LOG_FILE_MAX);
	this.hook531();
	this.hook545(waitTime);
	lastCheckpointMillis = 0;
	highestFlushLevel = IN.MIN_LEVEL;
	logManager = envImpl.getLogManager();
    }

    public int getHighestFlushLevel() {
	return highestFlushLevel;
    }

    /** 
     * Figure out the wakeup period. Supplied through this static method because we need to pass wakeup period to the superclass and need to do the calcuation outside this constructor.
     */
    public static long getWakeupPeriod(DbConfigManager configManager)
	    throws IllegalArgumentException, DatabaseException {
	return new Checkpointer_getWakeupPeriod(configManager).execute();
    }

    /** 
     * Set checkpoint id -- can only be done after recovery.
     */
    synchronized public void setCheckpointId(long lastCheckpointId) {
	checkpointId = lastCheckpointId;
    }

    /** 
     * @return the first active LSN point of the last completed checkpoint. Ifno checkpoint has run, return null.
     */
    public long getFirstActiveLsn() {
	return lastFirstActiveLsn;
    }

    /** 
     * Initialize the FirstActiveLsn during recovery. The cleaner needs this.
     */
    public void setFirstActiveLsn(long lastFirstActiveLsn) {
	this.lastFirstActiveLsn = lastFirstActiveLsn;
    }

    /** 
     * Determine whether a checkpoint should be run. 1. If the force parameter is specified, always checkpoint. 2. If the config object specifies time or log size, use that. 3. If the environment is configured to use log size based checkpointing, check the log. 4. Lastly, use time based checking.
     */
    private boolean isRunnable(CheckpointConfig config) throws DatabaseException {
	return new Checkpointer_isRunnable(this, config).execute();
    }

    /** 
     * The real work to do a checkpoint. This may be called by the checkpoint thread when waking up, or it may be invoked programatically through the api.
     * @param allowDeltasif true, this checkpoint may opt to log BIN deltas instead ofthe full node.
     * @param flushAllif true, this checkpoint must flush all the way to the top ofthe dbtree, instead of stopping at the highest level last modified.
     * @param invokingSourcea debug aid, to indicate who invoked this checkpoint. (i.e.recovery, the checkpointer daemon, the cleaner, programatically)
     */
    public synchronized void doCheckpoint(CheckpointConfig config, boolean flushAll, String invokingSource)
	    throws DatabaseException {
	new Checkpointer_doCheckpoint(this, config, flushAll, invokingSource).execute();
    }

    /** 
     * Flush a FileSummaryLN node for each TrackedFileSummary that is currently active. Tell the UtilizationProfile about the updated file summary.
     */
    private void flushUtilizationInfo() throws DatabaseException {
	if (!DbInternal.getCheckpointUP(envImpl.getConfigManager().getEnvironmentConfig())) {
	    return;
	}
	UtilizationProfile profile = envImpl.getUtilizationProfile();
	TrackedFileSummary[] activeFiles = envImpl.getUtilizationTracker().getTrackedFiles();
	for (int i = 0; i < activeFiles.length; i += 1) {
	    profile.flushFileSummary(activeFiles[i]);
	}
    }

    /** 
     * Flush the nodes in order, from the lowest level to highest level. As a flush dirties its parent, add it to the dirty map, thereby cascading the writes up the tree. If flushAll wasn't specified, we need only cascade up to the highest level set at the start of checkpointing. Note that all but the top level INs and the BINDeltas are logged provisionally. That's because we don't need to process lower INs because the higher INs will end up pointing at them.
     */
    private void flushDirtyNodes(SortedMap dirtyMap, boolean flushAll, boolean allowDeltas, boolean flushExtraLevel,
	    long checkpointStart) throws DatabaseException {
	while (dirtyMap.size() > 0) {
	    Integer currentLevel = (Integer) dirtyMap.firstKey();
	    boolean logProvisionally = (currentLevel.intValue() != highestFlushLevel);
	    Set nodeSet = (Set) dirtyMap.get(currentLevel);
	    Iterator iter = nodeSet.iterator();
	    while (iter.hasNext()) {
		CheckpointReference targetRef = (CheckpointReference) iter.next();
		this.hook520();
		//this.hook546(dirtyMap, allowDeltas, checkpointStart, currentLevel, logProvisionally, targetRef);
		Label546:
    iter.remove();
	    }
	    dirtyMap.remove(currentLevel);
	    if (currentLevel.intValue() == highestFlushLevel) {
		break;
	    }
	}
    }

    /** 
     * Scan the INList for all dirty INs. Arrange them in level sorted map for level ordered flushing.
     */
    private SortedMap selectDirtyINs(boolean flushAll, boolean flushExtraLevel) throws DatabaseException {
	return new Checkpointer_selectDirtyINs(this, flushAll, flushExtraLevel).execute();
    }

    /** 
     * Flush the target IN.
     */
    private void flushIN(CheckpointReference targetRef, Map dirtyMap, int currentLevel, boolean logProvisionally,
	    boolean allowDeltas, long checkpointStart) throws DatabaseException {
	Tree tree = targetRef.db.getTree();
	boolean targetWasRoot = false;
	if (targetRef.isDbRoot) {
	    RootFlusher flusher = new RootFlusher(targetRef.db, logManager, targetRef.nodeId);
	    tree.withRootLatchedExclusive(flusher);
	    boolean flushed = flusher.getFlushed();
	    targetWasRoot = flusher.stillRoot();
	    if (flushed) {
		DbTree dbTree = targetRef.db.getDbEnvironment().getDbMapTree();
		dbTree.modifyDbRoot(targetRef.db);
		this.hook532();
	    }
	}
	if (!targetWasRoot) {
	    SearchResult result = tree.getParentINForChildIN(targetRef.nodeId, targetRef.containsDuplicates, false,
		    targetRef.mainTreeKey, targetRef.dupTreeKey, false, false, -1, null, false);
	    if (result.parent != null) {
		boolean mustLogParent = false;
		this.hook526(targetRef, dirtyMap, currentLevel, logProvisionally, allowDeltas, checkpointStart, tree,
			result, mustLogParent);
	    }
	}
    }

    /** 
     * @return true if this parent is appropriately 1 level above the child.
     */
    private boolean checkParentChildRelationship(SearchResult result, int childLevel) {
	if (result.childNotResident && !result.exactParentFound) {
	    return true;
	}
	int parentLevel = result.parent.getLevel();
	boolean isMapTree = (childLevel & IN.DBMAP_LEVEL) != 0;
	boolean isMainTree = (childLevel & IN.MAIN_LEVEL) != 0;
	boolean checkOk = false;
	if (isMapTree || isMainTree) {
	    if (parentLevel == (childLevel + 1)) {
		checkOk = true;
	    }
	} else {
	    if (childLevel == 1) {
		if (parentLevel == 2) {
		    checkOk = true;
		}
	    } else {
		if ((parentLevel == IN.BIN_LEVEL) || (parentLevel == childLevel + 1)) {
		    checkOk = true;
		}
	    }
	}
	return checkOk;
    }

    private String dumpParentChildInfo(SearchResult result, IN parent, long childNodeId, int currentLevel, Tree tree)
	    throws DatabaseException {
	StringBuffer sb = new StringBuffer();
	sb.append("ckptId=").append(checkpointId);
	sb.append(" result=").append(result);
	sb.append(" parent node=").append(parent.getNodeId());
	sb.append(" level=").append(parent.getLevel());
	sb.append(" child node=").append(childNodeId);
	sb.append(" level=").append(currentLevel);
	return sb.toString();
    }

    private boolean logTargetAndUpdateParent(IN target, IN parent, int index, boolean allowDeltas, long checkpointStart,
	    boolean logProvisionally) throws DatabaseException {
	target.latch(false);
	long newLsn = DbLsn.NULL_LSN;
	boolean mustLogParent = true;
	this.hook527(target, parent, allowDeltas, checkpointStart, logProvisionally, newLsn, mustLogParent);
	if (newLsn != DbLsn.NULL_LSN) {
	    this.hook533(target);
	    parent.updateEntry(index, newLsn);
	}
	return mustLogParent;
    }

    /** 
     * Add a node to the dirty map. The dirty map is keyed by level (Integers) and holds sets of IN references.
     */
    private void addToDirtyMap(Map dirtyMap, IN in) {
	Integer inLevel = new Integer(in.getLevel());
	Set inSet = (Set) dirtyMap.get(inLevel);
	if (inSet == null) {
	    inSet = new HashSet();
	    dirtyMap.put(inLevel, inSet);
	}
	inSet.add(new CheckpointReference(in.getDatabase(), in.getNodeId(), in.containsDuplicates(), in.isDbRoot(),
		in.getMainTreeKey(), in.getDupTreeKey()));
    }

    protected void hook520() throws DatabaseException {
    }

    protected void hook526(CheckpointReference targetRef, Map dirtyMap, int currentLevel, boolean logProvisionally,
	    boolean allowDeltas, long checkpointStart, Tree tree, SearchResult result, boolean mustLogParent)
	    throws DatabaseException {
	if (result.exactParentFound) {
	    IN renewedTarget = (IN) result.parent.getTarget(result.index);
	    if (renewedTarget == null) {
		mustLogParent = true;
	    } else {
		mustLogParent = logTargetAndUpdateParent(renewedTarget, result.parent, result.index, allowDeltas,
			checkpointStart, logProvisionally);
	    }
	} else {
	    if (result.childNotResident) {
		if (result.parent.getLevel() > currentLevel) {
		    mustLogParent = true;
		}
	    }
	}
	if (mustLogParent) {
	    assert checkParentChildRelationship(result, currentLevel) : dumpParentChildInfo(result, result.parent,
		    targetRef.nodeId, currentLevel, tree);
	    addToDirtyMap(dirtyMap, result.parent);
	}
    }

    protected void hook527(IN target, IN parent, boolean allowDeltas, long checkpointStart, boolean logProvisionally,
	    long newLsn, boolean mustLogParent) throws DatabaseException {
	if (target.getDirty()) {
	    newLsn = target.log(logManager, allowDeltas, logProvisionally, true, parent);
	    if (allowDeltas && newLsn == DbLsn.NULL_LSN) {
		this.hook537();
		long lastFullLsn = target.getLastFullVersion();
		if (DbLsn.compareTo(lastFullLsn, checkpointStart) < 0) {
		    mustLogParent = false;
		}
	    }
	}
    }

    protected void hook531() throws DatabaseException {
    }

    protected void hook532() throws DatabaseException {
    }

    protected void hook533(IN target) throws DatabaseException {
    }

    protected void hook537() throws DatabaseException {
    }

    protected void hook538(EnvironmentImpl envImpl, long waitTime, String name) throws DatabaseException {
    }

    protected void hook539(EnvironmentImpl envImpl) throws DatabaseException {
    }

    protected void hook545(long waitTime) throws DatabaseException {
    }

 //   protected void hook546(SortedMap dirtyMap, boolean allowDeltas, long checkpointStart, Integer currentLevel,
//	    boolean logProvisionally, CheckpointReference targetRef) throws DatabaseException {
 //   }

}
