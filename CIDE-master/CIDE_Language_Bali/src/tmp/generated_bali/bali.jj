// Automatically generated code.  Edit at your own risk!
// Generated by bali2javacc v2002.09.04.

//-----------------------------------//
// Options block:
//-----------------------------------//

options {
    CACHE_TOKENS = true ;
    JAVA_UNICODE_ESCAPE = true ;
    //OPTIMIZE_TOKEN_MANAGER = true ;
    STATIC = false ;
}

//-----------------------------------//
// Parser code block:
//-----------------------------------//

PARSER_BEGIN(BaliParser)
package tmp.generated_bali;

import java.io.*;
import java.util.*;
import cide.gast.*;
import cide.gparser.*;

public class BaliParser {

    private static BaliParse parseRoot = null ;

    public static BaliParse getStartRoot () {
        return parseRoot ;
    }

	public ISourceFile getRoot() throws ParseException {
		return BaliParse();
	}



    //*************************************************************************
    // Code inserted from "bali.b" source grammar:
    //*************************************************************************

    /**
     * Append the given {@link Token} and any preceding special tokens to a
     * given {@link StringBuffer}.
     *
     * @param token the given JavaCC {@link Token} object
     * @param buffer the buffer to which to append <code>token</code>
     **/
    final private static void accumulate (Token token, StringBuffer buffer) {

	// Append preceding special tokens to <code>buffer</code>:
	//
	Token special = firstSpecial (token) ;
	if (special != token)
	    while (special != null) {
		buffer.append (special.toString ()) ;
		special = special.next ;
	    }

	// Finally, append the token itself:
	//
	buffer.append (token.toString ()) ;
    }
      
    /**
     * Accumulate {@list Token} objects from the token stream, respecting
     * nested code inside <code>open</code> and <code>close</code> pairs,
     * until an unmatched <code>close</code> is the next token in the stream.
     * This method assumes that an <code>open</code> token has just been read
     * from the stream so the initial nesting level is 1.  The method returns
     * when a matching <code>close</code> token is the next token in the token
     * stream.  <em>The <code>close</code> token is left in the stream!</em>
     *
     * @return the accumulated tokens as a {@link String}.
     *
     * @throws ParseException
     * if an end-of-file is found before an unmatched <code>close</code> token.
     **/
    final private Token accumulateNestedRegion (int open, int close)
    throws ParseException {

	StringBuffer buffer = new StringBuffer () ;

	// Initialize result with known information (starting position, etc.):
	//
	Token result = Token.newToken (OTHER) ;
	result.specialToken = null ;

	Token startToken = firstSpecial (getToken (1)) ;
	result.beginColumn = startToken.beginColumn ;
	result.beginLine = startToken.beginLine ;

	// Accumulate tokens until a <code>close</code> token is found:
	//
	for (int nesting = 1 ; nesting > 0 ; ) {

	    token = getToken (1) ;

	    // Update information in result:
	    //
	    result.endColumn = token.endColumn ;
	    result.endLine = token.endLine ;
	    result.next = token.next ;

	    if (token.kind == EOF)
		throw new ParseException (
		    "accumulating from line "
		    + result.beginLine
		    + " at column "
		    + result.beginColumn
		    + ": EOF reached before ending "
		    + tokenImage [close]
		    + " found"
		) ;

	    if (token.kind == open)
		++ nesting ;
	    else if (token.kind == close) {
		if (nesting == 1)
		    break ;
		-- nesting ;
	    }

	    accumulate (token, buffer) ;
	    getNextToken () ;
	}

	result.image = buffer.toString () ;
	return result ;
    }

    /**
     * Accumulate {@link Token} objects from the token stream until a token
     * matching <code>tokenKind</code> is consumed from the stream.  The
     * tokens are accumulated in <code>buffer</code>, including the terminating
     * token.
     *
     * @return a {@link Token}
     * formed by concatenating all intervening tokens and special tokens.
     **/
    final private Token accumulateUntilToken (int tokenKind)
    throws ParseException {

	StringBuffer buffer = new StringBuffer () ;
	Token token = getNextToken () ;

	// Initialize result with known information (starting position, etc.):
	//
	Token result = Token.newToken (OTHER) ;
	result.specialToken = null ;

	Token startToken = firstSpecial (token) ;
	result.beginColumn = startToken.beginColumn ;
	result.beginLine = startToken.beginLine ;

	// Accumulate tokens until a <code>tokenKind</code> token is found:
	//
	while (token.kind != tokenKind) {

	    // Update information in result:
	    //
	    result.endColumn = token.endColumn ;
	    result.endLine = token.endLine ;
	    result.next = token.next ;

	    if (token.kind == EOF)
		throw new ParseException (
		    "from line "
		    + result.beginLine
		    + " at column "
		    + result.beginColumn
		    + ": EOF reached before "
		    + tokenImage [tokenKind]
		    + " found"
		) ;

	    accumulate (token, buffer) ;
	    token = getNextToken () ;
	}

	accumulate (token, buffer) ;

	result.image = buffer.toString () ;
	return result ;
    }

    /**
     * Finds the first token, special or otherwise, in the list of special
     * tokens preceding this {@link Token}.  If this list is non-empty, the
     * result will be a special token.  Otherwise, it will be the starting
     * token.
     *
     * @param token the given {@link Token}.
     * @return the first special token preceding <code>token</code>.
     **/
    final private static Token firstSpecial (Token token) {

	while (token.specialToken != null)
	    token = token.specialToken ;

	return token ;
    }
}

PARSER_END(BaliParser)

//-----------------------------------//
// Token manager declarations:
//-----------------------------------//

// No TOKEN_MGR_DECLS defined in Bali grammar.

//-----------------------------------//
// Standard token definitions:
//-----------------------------------//

SPECIAL_TOKEN : {" "|"\f"|"\n"|"\r"|"\t"}

// COMMENTS:

MORE : {
    "//" : IN_SINGLE_LINE_COMMENT
    | <"/**" ~["/"]> { input_stream.backup(1); } : IN_FORMAL_COMMENT
    | "/*" : IN_MULTI_LINE_COMMENT
}

<IN_SINGLE_LINE_COMMENT>
SPECIAL_TOKEN : {
    <SINGLE_LINE_COMMENT: "\n" | "\n\r" | "\r" | "\r\n"> : DEFAULT
}

<IN_FORMAL_COMMENT>
SPECIAL_TOKEN : {
    <FORMAL_COMMENT: "*/" > : DEFAULT
}

<IN_MULTI_LINE_COMMENT>
SPECIAL_TOKEN : {
    <MULTI_LINE_COMMENT: "*/" > : DEFAULT
}

<IN_SINGLE_LINE_COMMENT,IN_FORMAL_COMMENT,IN_MULTI_LINE_COMMENT>
MORE : { < ~[] > }

TOKEN : {
    <#LETTER: ["a"-"z", "A"-"Z", "_", "$"]>
    | <#DIGIT: ["0"-"9"]>
}

//-----------------------------------//
// Bali tokens from grammar:
//-----------------------------------//

TOKEN : {
    <CLOSEANGLE: ">">
    | <CLOSEPAREN: ")">
    | <LBRACE: "{">
    | <OPENANGLE: "<">
    | <OPENPAREN: "(">
    | <RBRACE: "}">
    | <DOUBLECOLON: "::">
    | <COLON: ":">
    | <HASH: "#">
    | <STAR: "*">
    | <PLUS: "+">
    | <COMMA: ",">
    | <SCOLON: ";">
    | <SBOPEN: "[">
    | <SBCLOSE: "]">
    | <PIPE: "|">
    | <_CODE: "code">
    | <_EOF: "EOF">
    | <_IGNORE_CASE: "IGNORE_CASE">
    | <_JAVACODE: "JAVACODE">
    | <_LOOKAHEAD: "LOOKAHEAD">
    | <_MORE: "MORE">
    | <_OPTIONS: "options">
    | <_PARSER_BEGIN: "PARSER_BEGIN">
    | <_PARSER_END: "PARSER_END">
    | <_SKIP: "SKIP">
    | <_SPECIAL_TOKEN: "SPECIAL_TOKEN">
    | <_TOKEN: "TOKEN">
    | <_TOKEN_MGR_DECLS: "TOKEN_MGR_DECLS">
}

//-----------------------------------//
// Regular-expression tokens from grammar:
//-----------------------------------//

TOKEN: {
	<BALI_TOKEN: <UPPERCASE> (<UPPERCASE> | <DIGIT>)*> | 
	<#UPPERCASE: ["A"-"Z", "_", "$"]> | 
	<STRING:
		"\""
		( (~["\"","\\","\n","\r"])
		| ("\\"
		    ( ["n","t","b","r","f","\\","'","\""]
		    | ["0"-"7"] ( ["0"-"7"] )?
		    | ["0"-"3"] ["0"-"7"] ["0"-"7"]
		    )
		  )
		)*
		"\""
	> | 
	<INTEGER: (<DIGIT>)+>
}


TOKEN : {
    <IDENTIFIER: <LETTER> (<LETTER> | <DIGIT>)*>
    | <OTHER: ~[]>
}

//-----------------------------------//
// JAVACODE blocks from grammar:
//-----------------------------------//



JAVACODE
Token findBlockBegin () {
    return accumulateUntilToken (LBRACE) ;
}

JAVACODE
Token findBlockEnd () {
    return accumulateNestedRegion (LBRACE, RBRACE) ;
}

JAVACODE
Token findCloseAngle () {
    return accumulateNestedRegion (OPENANGLE, CLOSEANGLE) ;
}

JAVACODE
Token findCloseParen () {
    return accumulateNestedRegion (OPENPAREN, CLOSEPAREN) ;
}
BaliParse BaliParse() : { 
	OptionsNode optionsNode = null;
	ParserCode parserCode = null;
	Statements statements = null;
	Token firstToken=token;
} { (
	[optionsNode=OptionsNode()] [parserCode=ParserCode()] [statements=Statements()] 
	{return new BaliParse(optionsNode, parserCode, statements, firstToken.next,token);}
 ) }

OptionsNode OptionsNode() : { 
	Token t;
	ASTStringNode _options;
	Block block;
	ASTStringNode _options1;
	Token firstToken=token;
} { (
	t=<_OPTIONS>{_options=new ASTStringNode(t.image,new WToken(t));} block=Block() t=<_OPTIONS>{_options1=new ASTStringNode(t.image,new WToken(t));} 
	{return new OptionsNode(_options, block, _options1, firstToken.next,token);}
 ) }

ParserCode ParserCode() : { 
	Token t;
	ASTStringNode _code;
	Block block;
	ASTStringNode _code1;
	Token firstToken=token;
} { (
	t=<_CODE>{_code=new ASTStringNode(t.image,new WToken(t));} block=Block() t=<_CODE>{_code1=new ASTStringNode(t.image,new WToken(t));} 
	{return new ParserCode(_code, block, _code1, firstToken.next,token);}
 ) }

Block Block() : { 
	Token t;
	ASTStringNode findblockend;
	Token firstToken=token;
} { (
	"{" t=findBlockEnd(){findblockend=new ASTStringNode(t.image,new WToken(t));} "}" 
	{return new Block(findblockend, firstToken.next,token);}
 ) }

Statements Statements() : { 
	Statement statement;
	ArrayList<Statement> statementList = new ArrayList<Statement>();
	Token firstToken=token;
} { (
	(statement=Statement(){statementList.add(statement);})+ 
	{return new Statements(statementList, firstToken.next,token);}
 ) }

Statement Statement() : { 
	BaliGrammarRule baliGrammarRule;
	BaliTokenDefinition baliTokenDefinition;
	JavacodeProduction javacodeProduction;
	RegexTokenDefinition regexTokenDefinition;
	TokenManagerDeclarations tokenManagerDeclarations;
	Token firstToken=token;
} { (
	baliGrammarRule=BaliGrammarRule() 
	{return new Statement1(baliGrammarRule, firstToken.next,token);} |
	baliTokenDefinition=BaliTokenDefinition() 
	{return new Statement2(baliTokenDefinition, firstToken.next,token);} |
	javacodeProduction=JavacodeProduction() 
	{return new Statement3(javacodeProduction, firstToken.next,token);} |
	regexTokenDefinition=RegexTokenDefinition() 
	{return new Statement4(regexTokenDefinition, firstToken.next,token);} |
	tokenManagerDeclarations=TokenManagerDeclarations() 
	{return new Statement5(tokenManagerDeclarations, firstToken.next,token);}
 ) }

BaliTokenDefinition BaliTokenDefinition() : { 
	Token t;
	ASTStringNode string;
	ASTStringNode bali_token;
	Token firstToken=token;
} { (
	t=<STRING>{string=new ASTStringNode(t.image,new WToken(t));} t=<BALI_TOKEN>{bali_token=new ASTStringNode(t.image,new WToken(t));} 
	{return new BaliTokenDefinition(string, bali_token, firstToken.next,token);}
 ) }

JavacodeProduction JavacodeProduction() : { 
	Token t;
	ASTStringNode _javacode;
	ScanBlock scanBlock;
	Token firstToken=token;
} { (
	t=<_JAVACODE>{_javacode=new ASTStringNode(t.image,new WToken(t));} scanBlock=ScanBlock() 
	{return new JavacodeProduction(_javacode, scanBlock, firstToken.next,token);}
 ) }

TokenManagerDeclarations TokenManagerDeclarations() : { 
	Token t;
	ASTStringNode _token_mgr_decls;
	ScanBlock scanBlock;
	Token firstToken=token;
} { (
	t=<_TOKEN_MGR_DECLS>{_token_mgr_decls=new ASTStringNode(t.image,new WToken(t));} ":" scanBlock=ScanBlock() 
	{return new TokenManagerDeclarations(_token_mgr_decls, scanBlock, firstToken.next,token);}
 ) }

ScanBlock ScanBlock() : { 
	Token t;
	ASTStringNode findblockbegin;
	ASTStringNode findblockend;
	Token firstToken=token;
} { (
	t=findBlockBegin(){findblockbegin=new ASTStringNode(t.image,new WToken(t));} t=findBlockEnd(){findblockend=new ASTStringNode(t.image,new WToken(t));} "}" 
	{return new ScanBlock(findblockbegin, findblockend, firstToken.next,token);}
 ) }

BaliGrammarRule BaliGrammarRule() : { 
	Token t;
	ASTStringNode identifier;
	Production production;
	ArrayList<Production> list0=new ArrayList<Production>();
	Production production1;
	ArrayList<Production> production1List = new ArrayList<Production>();
	Token firstToken=token;
} { (
	t=<IDENTIFIER>{identifier=new ASTStringNode(t.image,new WToken(t));} ":" production=Production(){list0.add(production);} ("|" production1=Production(){list0.add(production1);})* ";" 
	{return new BaliGrammarRule(list0, identifier, firstToken.next,token);}
 ) }

Production Production() : { 
	Lookahead lookahead = null;
	Rewrite rewrite;
	Token firstToken=token;
} { (
	[lookahead=Lookahead()] rewrite=Rewrite() 
	{return new Production(lookahead, rewrite, firstToken.next,token);}
 ) }

Lookahead Lookahead() : { 
	Token t;
	ASTStringNode _lookahead;
	ASTStringNode findcloseparen;
	Token firstToken=token;
} { (
	t=<_LOOKAHEAD>{_lookahead=new ASTStringNode(t.image,new WToken(t));} "(" t=findCloseParen(){findcloseparen=new ASTStringNode(t.image,new WToken(t));} ")" 
	{return new Lookahead(_lookahead, findcloseparen, firstToken.next,token);}
 ) }

Rewrite Rewrite() : { 
	Lookahead lookahead = null;
	Primitive primitive;
	Primitive primitive1;
	PrimitiveRewrite primitiveRewrite;
	Token firstToken=token;
} { (
	"(" [lookahead=Lookahead()] primitive=Primitive() ")" "+" 
	{return new SimpleListNode(lookahead, primitive, firstToken.next,token);} |
	primitive1=Primitive() primitiveRewrite=PrimitiveRewrite() 
	{return new PrimitiveRewriteNode(primitive1, primitiveRewrite, firstToken.next,token);}
 ) }

PrimitiveRewrite PrimitiveRewrite() : { 
	Lookahead lookahead = null;
	Primitive primitive;
	Primitive primitive1;
	Pattern pattern = null;
	ClassName className = null;
	Token firstToken=token;
} { (
	"(" [lookahead=Lookahead()] primitive=Primitive() primitive1=Primitive() ")" "*" 
	{return new ComplexListNode(lookahead, primitive, primitive1, firstToken.next,token);} |
	[pattern=Pattern()] [className=ClassName()] 
	{return new PatternNode(pattern, className, firstToken.next,token);}
 ) }

Pattern Pattern() : { 
	Primitive primitive;
	ArrayList<Primitive> primitiveList = new ArrayList<Primitive>();
	Token firstToken=token;
} { (
	(primitive=Primitive(){primitiveList.add(primitive);})+ 
	{return new Pattern(primitiveList, firstToken.next,token);}
 ) }

ClassName ClassName() : { 
	Token t;
	ASTStringNode identifier;
	Token firstToken=token;
} { (
	"::" t=<IDENTIFIER>{identifier=new ASTStringNode(t.image,new WToken(t));} 
	{return new ClassName(identifier, firstToken.next,token);}
 ) }

Primitive Primitive() : { 
	IASTNode optionalNode;
	Terminal terminal;
	Token firstToken=token;
} { (
	optionalNode=OptionalNode() 
	{return new Primitive1(optionalNode, firstToken.next,token);} |
	terminal=Terminal() 
	{return new Primitive2(terminal, firstToken.next,token);}
 ) }

OptionalNode OptionalNode() : { 
	Lookahead lookahead = null;
	Terminal terminal;
	Token firstToken=token;
} { (
	"[" [lookahead=Lookahead()] terminal=Terminal() "]" 
	{return new OptionalNode(lookahead, terminal, firstToken.next,token);}
 ) }

Terminal Terminal() : { 
	Token t;
	ASTStringNode bali_token;
	ASTStringNode identifier;
	ASTStringNode string;
	Token firstToken=token;
} { (
	t=<BALI_TOKEN>{bali_token=new ASTStringNode(t.image,new WToken(t));} 
	{return new BaliTokenNode(bali_token, firstToken.next,token);} |
	t=<IDENTIFIER>{identifier=new ASTStringNode(t.image,new WToken(t));} 
	{return new IdentifierNode(identifier, firstToken.next,token);} |
	t=<STRING>{string=new ASTStringNode(t.image,new WToken(t));} 
	{return new StringNode(string, firstToken.next,token);}
 ) }

RegexTokenDefinition RegexTokenDefinition() : { 
	StateSet stateSet = null;
	REKind rEKind;
	CaseFlag caseFlag = null;
	REList rEList;
	Token firstToken=token;
} { (
	[stateSet=StateSet()] rEKind=REKind() [caseFlag=CaseFlag()] ":" "{" rEList=REList() "}" 
	{return new RegexTokenDefinition(stateSet, rEKind, caseFlag, rEList, firstToken.next,token);}
 ) }

StateSet StateSet() : { 
	StatesSpecifier statesSpecifier;
	Token firstToken=token;
} { (
	"<" statesSpecifier=StatesSpecifier() ">" 
	{return new StateSet(statesSpecifier, firstToken.next,token);}
 ) }

StatesSpecifier StatesSpecifier() : { 
	StatesList statesList;
	Token firstToken=token;
} { (
	"*"  
	{return new StarStatesNode(firstToken.next,token);} |
	statesList=StatesList() 
	{return new ListStatesNode(statesList, firstToken.next,token);}
 ) }

StatesList StatesList() : { 
	StateName stateName;
	ArrayList<StateName> list0=new ArrayList<StateName>();
	StateName stateName1;
	ArrayList<StateName> stateName1List = new ArrayList<StateName>();
	Token firstToken=token;
} { (
	stateName=StateName(){list0.add(stateName);} ("," stateName1=StateName(){list0.add(stateName1);})* 
	{return new StatesList(list0, firstToken.next,token);}
 ) }

StateName StateName() : { 
	Token t;
	ASTStringNode bali_token;
	Token firstToken=token;
} { (
	t=<BALI_TOKEN>{bali_token=new ASTStringNode(t.image,new WToken(t));} 
	{return new StateName(bali_token, firstToken.next,token);}
 ) }

REKind REKind() : { 
	Token t;
	ASTStringNode _token;
	ASTStringNode _special_token;
	ASTStringNode _skip;
	ASTStringNode _more;
	Token firstToken=token;
} { (
	t=<_TOKEN>{_token=new ASTStringNode(t.image,new WToken(t));} 
	{return new TokenKindNode(_token, firstToken.next,token);} |
	t=<_SPECIAL_TOKEN>{_special_token=new ASTStringNode(t.image,new WToken(t));} 
	{return new SpecialKindNode(_special_token, firstToken.next,token);} |
	t=<_SKIP>{_skip=new ASTStringNode(t.image,new WToken(t));} 
	{return new SkipKindNode(_skip, firstToken.next,token);} |
	t=<_MORE>{_more=new ASTStringNode(t.image,new WToken(t));} 
	{return new MoreKindNode(_more, firstToken.next,token);}
 ) }

CaseFlag CaseFlag() : { 
	Token t;
	ASTStringNode _ignore_case;
	Token firstToken=token;
} { (
	"[" t=<_IGNORE_CASE>{_ignore_case=new ASTStringNode(t.image,new WToken(t));} "]" 
	{return new CaseFlag(_ignore_case, firstToken.next,token);}
 ) }

REList REList() : { 
	RegexBlock regexBlock;
	ArrayList<RegexBlock> list0=new ArrayList<RegexBlock>();
	RegexBlock regexBlock1;
	ArrayList<RegexBlock> regexBlock1List = new ArrayList<RegexBlock>();
	Token firstToken=token;
} { (
	regexBlock=RegexBlock(){list0.add(regexBlock);} ("|" regexBlock1=RegexBlock(){list0.add(regexBlock1);})* 
	{return new REList(list0, firstToken.next,token);}
 ) }

RegexBlock RegexBlock() : { 
	Regex regex;
	Block block = null;
	NextState nextState = null;
	Token firstToken=token;
} { (
	regex=Regex() [block=Block()] [nextState=NextState()] 
	{return new RegexBlock(regex, block, nextState, firstToken.next,token);}
 ) }

NextState NextState() : { 
	Token t;
	ASTStringNode bali_token;
	Token firstToken=token;
} { (
	":" t=<BALI_TOKEN>{bali_token=new ASTStringNode(t.image,new WToken(t));} 
	{return new NextState(bali_token, firstToken.next,token);}
 ) }

Regex Regex() : { 
	Token t;
	ASTStringNode string;
	AngleRegex angleRegex;
	Token firstToken=token;
} { (
	t=<STRING>{string=new ASTStringNode(t.image,new WToken(t));} 
	{return new StringRegexNode(string, firstToken.next,token);} |
	"<" angleRegex=AngleRegex() 
	{return new AngleRegexNode(angleRegex, firstToken.next,token);}
 ) }

AngleRegex AngleRegex() : { 
	Token t;
	ASTStringNode bali_token;
	Label label = null;
	ComplexRegex complexRegex;
	Token firstToken=token;
} { (
	LOOKAHEAD(2) t=<BALI_TOKEN>{bali_token=new ASTStringNode(t.image,new WToken(t));} ">" 
	{return new BaliRegexNode(bali_token, firstToken.next,token);} |
	LOOKAHEAD(2) [label=Label()] complexRegex=ComplexRegex() 
	{return new ComplexRegexNode(label, complexRegex, firstToken.next,token);}
 ) }

ComplexRegex ComplexRegex() : { 
	Token t;
	ASTStringNode string;
	ASTStringNode findcloseangle;
	Token firstToken=token;
} { (
	LOOKAHEAD(2) t=<STRING>{string=new ASTStringNode(t.image,new WToken(t));} ">" 
	{return new StringComplexNode(string, firstToken.next,token);} |
	t=findCloseAngle(){findcloseangle=new ASTStringNode(t.image,new WToken(t));} ">" 
	{return new AngleComplexNode(findcloseangle, firstToken.next,token);}
 ) }

Label Label() : { 
	ASTTextNode text17 = null;
	Token t;
	ASTStringNode bali_token;
	Token firstToken=token;
} { (
	["#" {text17=new ASTTextNode("#",new WToken(token));}] t=<BALI_TOKEN>{bali_token=new ASTStringNode(t.image,new WToken(t));} ":" 
	{return new Label(text17, bali_token, firstToken.next,token);}
 ) }

