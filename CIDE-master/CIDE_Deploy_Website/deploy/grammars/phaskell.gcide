
options {
  STATIC = false;
}

PARSER_BEGIN(HaskellParser)

package tmp.generated_phaskell;

import java.io.*;
import java.util.*;
import cide.gast.*;
import cide.gparser.*;

  public class HaskellParser{

	/**
	 * Append the given {@link Token} and any preceding special tokens to a
	 * given {@link StringBuffer}.
	 * 
	 * @param token
	 *            the given JavaCC {@link Token} object
	 * @param buffer
	 *            the buffer to which to append <code>token</code>
	 */
	final private static void accumulate(Token token, StringBuffer buffer) {

		// Append preceding special tokens to <code>buffer</code>:
		//
		Token special = firstSpecial(token);
		if (special != token)
			while (special != null) {
				buffer.append(special.toString());
				special = special.next;
			}

		// Finally, append the token itself:
		//
		buffer.append(token.toString());
	}

	/**
	 * Accumulate {@list Token} objects from the token stream, respecting nested
	 * code inside <code>open</code> and <code>close</code> pairs, until an
	 * unmatched <code>close</code> is the next token in the stream. This
	 * method assumes that an <code>open</code> token has just been read from
	 * the stream so the initial nesting level is 1. The method returns when a
	 * matching <code>close</code> token is the next token in the token
	 * stream. <em>The <code>close</code> token is left in the stream!</em>
	 * 
	 * @return the accumulated tokens as a {@link String}.
	 * 
	 * @throws ParseException
	 *             if an end-of-file is found before an unmatched
	 *             <code>close</code> token.
	 */
	final private Token accumulateNestedRegion(int open, int close)
			throws ParseException {

		StringBuffer buffer = new StringBuffer();
		Token token = getToken(1);

		// Initialize result with known information (starting position, etc.):
		//
		Token result = Token.newToken(UNANTICIPATED_SYMBOL);
		result.specialToken = null;

		Token startToken = firstSpecial(token);
		result.beginColumn = startToken.beginColumn;
		result.beginLine = startToken.beginLine;
		result.offset=startToken.offset;

		// Accumulate tokens until a <code>close</code> token is found:
		//
		for (int nesting = 1; nesting > 0;) {


			if (token.kind == EOF)
				throw new ParseException("accumulating from line "
						+ result.beginLine + " at column " + result.beginColumn
						+ ": EOF reached before ending " + tokenImage[close]
						+ " found");

			if (token.kind == open)
				++nesting;
			else if (token.kind == close) {
				if (nesting == 1)
					break;
				--nesting;
			}

			// Update information in result:
			//
			result.endColumn = token.endColumn;
			result.endLine = token.endLine;
			result.length=(token.offset-result.offset)+token.length;
			result.next = token.next;

			accumulate(token, buffer);
			getNextToken();
			token = getToken(1);
		}

		result.image = buffer.toString();
		return result;
	}


	final private Token accumulateUntil(boolean considerInnerBlocks,
			int endTokenKind) throws ParseException {
		return accumulateUntil(considerInnerBlocks, new int[] { endTokenKind });
	}

	final private Token accumulateUntil(boolean considerInnerBlocks,
			int endTokenKind1, int endTokenKind2) throws ParseException {
		return accumulateUntil(considerInnerBlocks, new int[] { endTokenKind1,
				endTokenKind2 });
	}

	final private Token accumulateUntil(boolean considerInnerBlocks,
			int endTokenKind1, int endTokenKind2, int endTokenKind3)
			throws ParseException {
		return accumulateUntil(considerInnerBlocks, new int[] { endTokenKind1,
				endTokenKind2, endTokenKind3 });
	}
	final private Token accumulateUntil(boolean considerInnerBlocks,
			int endTokenKind1, int endTokenKind2, int endTokenKind3, int endTokenKind4)
			throws ParseException {
		return accumulateUntil(considerInnerBlocks, new int[] { endTokenKind1,
				endTokenKind2, endTokenKind3, endTokenKind4 });
	}

	final private boolean isNot(int kind) {
		return getToken(1).kind != kind;
	}

	final private boolean isNot(int k1, int k2) {
		return isNot(k1) && isNot(k2);
	}

	final private boolean isNot(int k1, int k2, int k3) {
		return isNot(k1, k2) && isNot(k3);
	}
	final private boolean isNot(int k1, int k2, int k3, int k4) {
		return isNot(k1, k2, k3) && isNot(k4);
	}
	
	/** returns true if the CONTEXT_ARROW is found before the SEMICOLON **/
	final private boolean isContext() throws ParseException {
		int lookahead=1;
		while (true) {
			Token t = getToken(lookahead);
			if (t.kind==EOF) throw new ParseException("EOF found before ; or =>  (line " + token.beginLine
                                                + ", column " + token.beginColumn
                                                + ")");
			if (t.kind==SEMICOLON) return false;
			if (t.kind==CONTEXT_ARROW) return true;	
			lookahead++;
		}
	}

	/**
	 * Accumulate {@link Token} objects from the token stream until a token
	 * matching <code>tokenKind</code> is consumed from the stream. The tokens
	 * are accumulated in <code>buffer</code>, NOT including the terminating
	 * token.
	 * 
	 * @return a {@link Token} formed by concatenating all intervening tokens
	 *         and special tokens.
	 */
	final private Token accumulateUntil(boolean considerInnerBlocks,
			int[] endTokenKinds) throws ParseException {

		StringBuffer buffer = new StringBuffer();
		Token token = getToken(1);

		// Initialize result with known information (starting position, etc.):
		//
		Token result = Token.newToken(UNANTICIPATED_SYMBOL);
		result.specialToken = null;

		Token startToken = firstSpecial(token);
		result.beginColumn = startToken.beginColumn;
		result.beginLine = startToken.beginLine;
		result.offset=startToken.offset;

		// Accumulate tokens until a <code>tokenKind</code> token is found:
		//
		int nesting=0;
		while (!contains(endTokenKinds, token.kind) || nesting >0) {
			// Update information in result:
			//
			result.endColumn = token.endColumn;
			result.endLine = token.endLine;
			result.next = token.next;
			result.length=(token.offset-result.offset)+token.length;

			if (token.kind == EOF)
				throw new ParseException("from line " + result.beginLine
						+ " at column " + result.beginColumn
						+ ": EOF reached before " + images(endTokenKinds)
						+ " found");
			
			if (considerInnerBlocks && token.kind == LEFT_CURLY)
				++nesting;
			else if (considerInnerBlocks && token.kind == RIGHT_CURLY) {
				--nesting;
			}

			accumulate(token, buffer);
			getNextToken();
			token = getToken(1);
		}

		if (buffer.length() == 0)
			throw new ParseException("syntax error - empty pseudo-match (line " + result.beginLine
                                                + ", column " + result.beginColumn
                                                + ")");

		result.image = buffer.toString();
		return result;
	}

	private String images(int[] endTokenKinds) {
		String result = "";
		for (int i : endTokenKinds)
			result += tokenImage[i] + " ";
		return result;
	}

	private boolean contains(int[] endTokenKinds, int kind) {
		for (int i : endTokenKinds)
			if (i == kind)
				return true;
		return false;
	}

    /**
     * Finds the first token, special or otherwise, in the list of special
     * tokens preceding this {@link Token}.  If this list is non-empty, the
     * result will be a special token.  Otherwise, it will be the starting
     * token.
     *
     * @param token the given {@link Token}.
     * @return the first special token preceding <code>token</code>.
     **/
    final private static Token firstSpecial (Token token) {

	while (token.specialToken != null)
	    token = token.specialToken ;

	return token ;
    }
  }

PARSER_END(HaskellParser)


JAVACODE
Token findListContent () {
    return accumulateNestedRegion(LEFT_PAREN, RIGHT_PAREN) ;
}

JAVACODE
Token findBlockContent () {
    return accumulateNestedRegion (LEFT_CURLY, RIGHT_CURLY) ;
}

JAVACODE
Token findConRest () {
	//(block | ~(SEMICOLON|ALT|RIGHT_CURLY))*
    return accumulateUntil(true,SEMICOLON,ALT,RIGHT_CURLY,DERIVING) ;
}

JAVACODE
Token findNonstddeclRest () {
	//(block | ~(SEMICOLON|RIGHT_CURLY))+
    return accumulateUntil(true,SEMICOLON,RIGHT_CURLY) ;
}

JAVACODE
Token findUntilSemiOrCCB () {
	//~(SEMICOLON | RIGHT_CURLY)*
    return accumulateUntil(false,SEMICOLON,RIGHT_CURLY) ;
}
JAVACODE
Token findUntilSemiOrContextArrow () {
	//(~(CONTEXT_ARROW|SEMICOLON))*;
    return accumulateUntil(false,CONTEXT_ARROW,SEMICOLON) ;
}
JAVACODE
Token findUntilSemiOrEquals () {
	//~(EQUALS|SEMICOLON))*
    return accumulateUntil(false,SEMICOLON,EQUALS) ;
}
JAVACODE
Token findUntilEquals () {
	//~(EQUALS))*
    return accumulateUntil(false,EQUALS) ;
}





//options	{
//    k = 9;
//    // Allow any char but \uFFFF (16 bit -1)
//    charVocabulary='\u0000'..'\uFFFE';
//}

TOKEN : {
	<MODULE : "module">
|	<WHERE : "where" >
|	<IMPORT : "import" >
|	<QUALIFIED : "qualified" >
|	<DERIVING : "deriving" >
|	<AS : "as" >
|	<HIDING : "hiding" >
|	<TYPE : "type" >
|	<DATA : "data" >
|	<NEWTYPE : "newtype" >
|	<CLASS : "class" >
|	<INSTANCE : "instance" >
|	<DEFAULTTOKEN : "default" >
|	<LET : "let" >
|	<DO : "do" >
|	<OF : "of" >
|	<INFIXL : "infixl" >
|	<INFIXR : "infixr" >
|	<INFIX : "infix" >
|	<CONTEXT_ARROW : "=>" >
|	<EQUALS : "=" >
|	<ALT : "|" >
|	<OFTYPE : "::" >
//|	<QVARID>//|	<QCONID>//|	<QVARSYM>
}

SPECIAL_TOKEN : {
 " "
|  "\t"
|  "\n"
|  "\r"
|  <"--" (~["\n","\r"])* ("\n" | "\r" | "\r\n")>
| <"{-"(~["-"])*"-"("-" | ~["-", "}"](~["-"])*"-")*"}">
}

    
//PPDIRECTIVE
//	:	'#' (~('\n'))* NEWLINE { $setType(Token.SKIP); }
//	;


TOKEN : {
	<CONSTRUCTOR_ID : <UPPER_CASE>	( <LETTER>
							| <DIGIT>
							| "'" )* >
|	<VARIABLE_ID : <LOWER_CASE>	( <LETTER>
							| <DIGIT>
							| "'" )*>

|	<INTEGER:	(<DECIMAL>	|	"0o" <OCTAL> | "0O" <OCTAL>
		|	"0x" <HEXADECIMAL> | "0X" <HEXADECIMAL>)>
		

|	<#DECIMAL : (<DIGIT>)+ >

|	<#HEXADECIMAL : (<HEXIT>)+>

|	<#OCTAL : (<OCTIT>)+ >

//|	<CHARACTER_LITERAL : "'" (~["'","\\"]|<CHARACTER_ESCAPE>) "'" >////|	<STRING_LITERAL : "\"" (~["\"","\\"]|<STRING_ESCAPE>|<GAP>)* "\"" >
|  < CHARACTER_LITERAL:
      "'"
      (   (~["'","\\","\n","\r"])
        | ("\\"
            ( ["n","t","b","r","f","\\","'","\""]
            | ["0"-"7"] ( ["0"-"7"] )?
            | ["0"-"3"] ["0"-"7"] ["0"-"7"]
            )
          )
      )
      "'"
  >
|
  < STRING_LITERAL:
      "\""
      (   (~["\"","\\","\n","\r"])
        | ("\\"
            ( ["n","t","b","r","f","\\","'","\""]
            | ["0"-"7"] ( ["0"-"7"] )?
            | ["0"-"3"] ["0"-"7"] ["0"-"7"]
            )
          )
      )*
      "\""
  >
|	<#CHARACTER_ESCAPE	:	"\\"
		( <CHAR_ESC>
		| <ASCII>
		| <DECIMAL>
		| "x" <HEXADECIMAL>
		| "o" <OCTAL>
		)
	>
	
|	<CHAR_ESC
	:
    	( "a"
    	| "b"  
    	| "f"  
    	| "n"  
    	| "r" 
    	| "t" 
    	| "v"
    	| "\\" 
    	| "\""
    	| "\'" )
	>

|	<#STRING_ESCAPE	: ("\\&" | <CHARACTER_ESCAPE>)>
    
    
|	<#ASCII : "NUL" >
    
//|	<NEWLINE : "\n">

//|	<#GAP : "\\" (<WS> | <NEWLINE>)+ "\\" >

|	<#LOWER_CASE:	["a"-"z","_"]>	
|	<#UPPER_CASE:	["A"-"Z"]>	
|	<#LETTER : <UPPER_CASE> | <LOWER_CASE>>

|	<#DIGIT:	["0"-"9"]>	

|	<#HEXIT:	(<DIGIT> | ["A"-"F"] | ["a"-"f"] )>	

|	<#OCTIT:	["0"-"7"]>	

|	<LEFT_CURLY : "{" >

|	<RIGHT_CURLY : "}" >

|	<SEMICOLON : ";" >

|	<LEFT_PAREN : "(" >

|	<RIGHT_PAREN : ")" >

|	<LEFT_BRACKET : "[" >

|	<RIGHT_BRACKET : "]" >

|	<COMMA : "," >

|	<INFIX_QUOTE : "`" >

|	<VARSYM : <SYMBOL> (<SYMBOL> | ":" )* >

|	<CONSYM : ":" (<SYMBOL> | ":" )* >

|	<SYMBOL : "!" | "#" | "$" | "%" | "&" | "*" | "+" | "." | "/" | "<" | "="
       | ">" | "?" | "@" | "\\" | "^" | "-" | "~" | "|"
       >
       
|	<UNANTICIPATED_SYMBOL : ~["a"-"z","A"-"Z","0"-"9"] >
}


<PAREN> TOKEN :{
 	<ANYTHINGP: ~["(",")"]>
}

GRAMMARSTART

module: 
      	"module"
        	modid
        	(exports)?
        	@! "where"
      	
      	body <EOF>
    ;
    
    
qconid :
//TODO		<QCONID>|
		<CONSTRUCTOR_ID>	;
		
exports
	:
	    "(" [exportsList] [","<NONE>] ")"
	;
exportsList: &LI export (LL(2) "," &LI export)*;
	
	
export : qvar
       | qtyconorcls [details] //-- type or class
       | "module" modid
       ;

details :
        LL(2) "(" <VARSYM> /*TODO ".."*/ ")"<NONE>
        | "(" [cnamelist] ")"  
        ;  
cnamelist: &LI cname ( "," &LI cname)*;
	
qtyconorcls: qconid;
    
	
cname:	<VARIABLE_ID> | <CONSTRUCTOR_ID>;
		
qvar: qvarid |	"(" qvarsym ")"	;
	
qvarid: //TODO<QVARID>|
	<VARIABLE_ID>	;

qvarsym://TODO <QVARSYM>|
	<VARSYM>;
	
modid:qconid;

conid:<CONSTRUCTOR_ID>;
	
body : LL(2) "{" @+! impdecls [ ";"@! @! topdecls] @-! "}"
     | "{" @+! topdecls @-! "}"
     ;	
		
impdecls
	:
		&LI impdecl	( LL(2) ";" @! &LI impdecl )*
	;

impdecl: 
		"import" ("qualified"<NONE>)? modid ("as" modid)?
		(  impspec )?
	| <NONE>//empty declaration
	;

impspec : ("hiding"<NONE> )? "(" [imports] ")" ; //-- should allow a trailing comma!

imports : imp (LL("\",\" imp()") "," imp)*  ;

imp: var
       | tyconorcls [list];
	
	
tyconorcls: conid;

topdecls: &LI topdecl	( ";"@! @! &LI topdecl )* 	;

topdecl :	"type"		simpletype		declrhs	 :: typedecl
	|   "data" optContext simpletype "=" constrs [deriving] :: datadecl
	|	"newtype"  optContext simpletype declrhs  :: newtypedecl
	|   "class"    optContext conid tyvar ("where" cdecls)? :: classdecl
    |   "instance" optContext qconid inst ("where" block)?  :: instancedecl
	|   "default" list  :: defaultdecl
	|   decl :: declaration
	;
	
decl: LL("vars() \"::\"") signdecl	:: typeSignature
	|   fixdecl						:: fixityDeclaration
	|	LL("funlhs() \"=\"") valdef :: valueDeclaration
	|	nonstddecl 					:: nonStandardDeclaration
	|   <NONE>//empty declaration
	;	

declrhs: "=" [LL("{isNot(SEMICOLON,RIGHT_CURLY)}") JAVATOKEN(findNonstddeclRest)]; 
	
optContext: [LL("{isContext()}") context "=>"];
	
deriving : "deriving" JAVATOKEN(findNonstddeclRest) ;

	
constrs	:		&LI constr ("|" &LI constr)*	;
	
constr: conP [LL("{isNot(SEMICOLON,ALT,RIGHT_CURLY,DERIVING)}")  JAVATOKEN(findConRest)];


inst: gtycon
	|   "(" gtycon (tyvar)* ")"
	|	"[" conid "]" ;

gtycon: qtyconorcls;

cdecls:		"{"	( cdeclsI )?	"}"	;

cdeclsI: &LI cdecl (";"@! @! &LI cdecl)*;

cdecl:	LL("vars() \"::\"") signdecl
	|	nonstddecl;

context: [LL("{isNot(SEMICOLON,CONTEXT_ARROW)}") JAVATOKEN(findUntilSemiOrContextArrow)];//(~(CONTEXT_ARROW|SEMICOLON))*;

simpletype: <CONSTRUCTOR_ID> [LL("{isNot(EQUALS)}") JAVATOKEN(findUntilEquals)];
	

	
//matches almost anything
//used to ignore non-standard declarations	
nonstddecl	:	JAVATOKEN(findNonstddeclRest)	;

//the valdef rule doesn't come directly from the report spec
//it is inherited from the Language.Haskell.Parser impl
valdef: funlhs declrhs	;

//the fixdecl rule also doesn't come directly from the report spec
fixdecl: fixity [<INTEGER>] ops;
	
fixity:	"infixl"
	|	"infixr"
	|	"infix";
	
ops:		&LI op 	("," &LI op )*	;
	

signdecl: vars "::"	[LL("{isNot(SEMICOLON,RIGHT_CURLY)}")  JAVATOKEN(findUntilSemiOrCCB)];
	
vars: &LI var ("," &LI var)*;
	
var : <VARIABLE_ID>
	|	"(" <VARSYM> ")"	;

conP: <CONSTRUCTOR_ID>
	|	"(" <CONSYM> ")"	;

tyvar : <VARIABLE_ID> ;

funlhs: funlhsL [LL("{isNot(SEMICOLON,EQUALS,LEFT_CURLY)}") funlhsR];
funlhsL: LL("<VARIABLE_ID> varop()")	 <VARIABLE_ID> varop | var;	
funlhsR: block | LL("{isNot(SEMICOLON,EQUALS)}")  JAVATOKEN(findUntilSemiOrEquals);
	
varop:	<VARSYM>
	|	"`"		<VARIABLE_ID>		"`"	;
	
conop:	<CONSYM>
	|	"`" <CONSTRUCTOR_ID> "`";
	
op: LL(2) varop | conop;



	
block : "{" [LL("{isNot(RIGHT_CURLY)}") JAVATOKEN(findBlockContent)] "}";list : "(" [LL("{isNot(RIGHT_PAREN)}") JAVATOKEN(findListContent)] ")";

