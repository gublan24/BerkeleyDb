namespace com.sleepycat.je.cleaner;

class FileProcessor {
 isA DaemonThread;
 depend com.sleepycat.je.utilint.Tracer;
 depend com.sleepycat.je.utilint.DbLsn;
 depend com.sleepycat.je.utilint.DaemonThread;
 depend com.sleepycat.je.txn.LockType;
 depend com.sleepycat.je.txn.LockResult;
 depend com.sleepycat.je.txn.LockGrantType;
 depend com.sleepycat.je.txn.BasicLocker;
 depend com.sleepycat.je.tree.WithRootLatched;
 depend com.sleepycat.je.tree.TreeLocation;
 depend com.sleepycat.je.tree.Tree;
 depend com.sleepycat.je.tree.SearchResult;
 depend com.sleepycat.je.tree.LN;
 depend com.sleepycat.je.tree.IN;
 depend com.sleepycat.je.tree.DIN;
 depend com.sleepycat.je.tree.ChildReference;
 depend com.sleepycat.je.tree.BIN;
 depend com.sleepycat.je.log.CleanerFileReader;
 depend com.sleepycat.je.dbi.MemoryBudget;
 depend com.sleepycat.je.dbi.EnvironmentImpl;
 depend com.sleepycat.je.dbi.DbTree;
 depend com.sleepycat.je.dbi.DatabaseImpl;
 depend com.sleepycat.je.dbi.DatabaseId;
 depend com.sleepycat.je.DatabaseException;
 depend java.util.logging.Level;
 depend java.util.TreeMap;
 depend java.util.SortedMap;
 depend java.util.Set;
 depend java.util.Map;
 depend java.util.Iterator;
 depend java.util.HashSet;
 depend java.util.HashMap;
 depend java.io.IOException;
 /** 
  * The number of LN log entries after we process pending LNs. If we do this too seldom, the pending LN queue may grow large, and it isn't budgeted memory. If we process it too often, we will repeatedly request a non-blocking lock for the same locked node.
  */
 private static final int PROCESS_PENDING_EVERY_N_LNS = 100;

 /** 
  * Whether to prohibit BINDeltas for a BIN that is fetched by the cleaner. The theory is that when fetching a BIN during cleaning we normally expect that the BIN will be evicted soon, and a delta during checkpoint would be wasted. However, this does not take into account use of the BIN by the application after fetching; the BIN could become hot and then deltas may be profitable. To be safe we currently allow deltas when fetching.
  */
 private static final boolean PROHIBIT_DELTAS_WHEN_FETCHING = false;

 private static final boolean DEBUG_TRACING = false;

 private EnvironmentImpl env;

 protected Cleaner cleaner;

 private FileSelector fileSelector;

 private UtilizationProfile profile;

 FileProcessor(String name, EnvironmentImpl env, Cleaner cleaner, UtilizationProfile profile,
  FileSelector fileSelector) {
  super(0, name, env);
  this.env = env;
  this.cleaner = cleaner;
  this.fileSelector = fileSelector;
  this.profile = profile;
 }

 public void clearEnv() {
  env = null;
  cleaner = null;
  fileSelector = null;
  profile = null;
 }

 /** 
  * Return the number of retries when a deadlock exception occurs.
  */
 protected int nDeadlockRetries() throws DatabaseException {
  return cleaner.nDeadlockRetries;
 }

 /** 
  * Cleaner doesn't have a work queue so just throw an exception if it's ever called.
  */
 public void addToQueue(Object o) throws DatabaseException {
  throw new DatabaseException("Cleaner.addToQueue should never be called.");
 }

 /** 
  * Activates the cleaner. Is normally called when je.cleaner.byteInterval bytes are written to the log.
  */
 public void onWakeup() throws DatabaseException {
  doClean(true, true, false);
 }

 /** 
  * Cleans selected files and returns the number of files cleaned. May be called by the daemon thread or programatically.
  * @param invokedFromDaemoncurrently has no effect.
  * @param cleanMultipleFilesis true to clean until we're under budget, or false to cleanat most one file.
  * @param forceCleaningis true to clean even if we're not under the utilizationthreshold.
  * @return the number of files cleaned, not including files cleanedunsuccessfully.
  */
 public synchronized int doClean(boolean invokedFromDaemon, boolean cleanMultipleFiles, boolean forceCleaning)
 throws DatabaseException {
  if (env.isClosed()) {
   return 0;
  }
  int nOriginalLogFiles = profile.getNumberOfFiles();
  int nFilesCleaned = 0;
  while (true) {
   if (nFilesCleaned >= nOriginalLogFiles) {
    break;
   }
   if (env.isClosing()) {
    break;
   }
   cleaner.processPending();
   cleaner.deleteSafeToDeleteFiles();
   boolean needLowUtilizationSet = cleaner.clusterResident || cleaner.clusterAll;
   Long fileNum = fileSelector.selectFileForCleaning(profile, forceCleaning, needLowUtilizationSet,
    cleaner.maxBatchFiles);
   cleaner.updateReadOnlyFileCollections();
   if (fileNum == null) {
    break;
   }
   Label138: ;//this.hook138();
    boolean finished = false;
   long fileNumValue = fileNum.longValue();
   int runId = ++cleaner.nCleanerRuns;
   try {
    String traceMsg = "CleanerRun " + runId + " on file 0x" + Long.toHexString(fileNumValue);
    Label139:   ; //traceMsg = this.hook139(traceMsg);
     Label121:   ; //this.hook121(traceMsg);
     if (DEBUG_TRACING) {
      System.out.println("\n" + traceMsg);
     }
    if (processFile(fileNum)) {
     fileSelector.addCleanedFile(fileNum);
     nFilesCleaned += 1;
     Label140:   ; //this.hook140();
      finished = true;
    }
   } catch (IOException IOE) {
    Label122:   ; //this.hook122(IOE);
     throw new DatabaseException(IOE);
   }
   finally {
    if (!finished) {
     fileSelector.putBackFileForCleaning(fileNum);
    }
    String traceMsg = "CleanerRun " + runId + " on file 0x" + Long.toHexString(fileNumValue) +
     " invokedFromDaemon=" + invokedFromDaemon + " finished=" + finished;
    Label141:   ; //traceMsg = this.hook141(traceMsg);
     Label123:   ; //this.hook123(traceMsg);
     if (DEBUG_TRACING) {
      System.out.println("\n" + traceMsg);
     }
   }
   if (!cleanMultipleFiles) {
    break;
   }
  }
  return nFilesCleaned;
 }

 /** 
  * Process all log entries in the given file. Note that we check for obsolete entries using the active TFS (TrackedFileSummary) for a file while it is being processed, and we prohibit flushing (eviction) of that offset information until file processing is complete. An entry could become obsolete because: 1- normal application activity deletes or updates the entry, 2- proactive migration migrates the entry before we process it, or 3- if trackDetail is false. However, checking the TFS is expensive if it has many entries, because we perform a linear search. There is a tradeoff between the cost of the TFS lookup and its benefit, which is to avoid a tree search if the entry is obsolete. Note that many more lookups for non-obsolete entries than obsolete entries will typically be done. In spite of that we check the tracked summary to avoid the situation where eviction does proactive migration, and evicts a BIN that is very soon afterward fetched during cleaning.
  * @return false if we aborted file processing because the environment isbeing closed.
  */

private void processLN(Long fileNum, TreeLocation location, Long offset,
			LNInfo info, LookAheadCache lookAheadCache, Map dbCache)
			throws DatabaseException {



		/* Get the first LN from the queue. */
		Label132: ;

		LN ln = info.getLN();
		byte[] key = info.getKey();
		byte[] dupKey = info.getDupKey();

		long logLsn = DbLsn.makeLsn(fileNum.longValue(), offset.longValue());

		DatabaseImpl db = env.getDbMapTree().getDb(info.getDbId(),
				cleaner.lockTimeout, dbCache);

		/* Status variables are used to generate debug tracing info. */
		boolean processedHere = true; // The LN was cleaned here.
		boolean obsolete = false; // The LN is no longer in use.
		boolean completed = false; // This method completed.

		BIN bin = null;
		DIN parentDIN = null; // for DupCountLNs
		try {

			/*
			 * If the DB is gone, this LN is obsolete. If delete cleanup is in
			 * progress, put the DB into the DB pending set; this LN will be
			 * declared deleted after the delete cleanup is finished.
			 */
			if (db == null || db.isDeleted()) {
				cleaner.addPendingDB(db);
				Label148: ; 

				obsolete = true;
				completed = true;
				return;
			}

			Tree tree = db.getTree();
			assert tree != null;

			/*
			 * Search down to the bottom most level for the parent of this LN.
			 */
			boolean parentFound = tree.getParentBINForChildLN(location, key,
					dupKey, ln, false, // splitsAllowed
					true, // findDeletedEntries
					false, // searchDupTree
					Cleaner.UPDATE_GENERATION);
			bin = location.bin;
			int index = location.index;

			if (!parentFound) {
				Label150: ;
				obsolete = true;
				completed = true;
				return;
			}

			/*
			 * Now we're at the parent for this LN, whether BIN, DBIN or DIN. If
			 * knownDeleted, LN is deleted and can be purged.
			 */
			if (bin.isEntryKnownDeleted(index)) {
				Label149: ; 
				obsolete = true;
				completed = true;
				return;
			}

			/*
			 * Determine whether the parent is the current BIN, or in the case
			 * of a DupCountLN, a DIN. Get the tree LSN in either case.
			 */
			boolean isDupCountLN = ln.containsDuplicates();
			long treeLsn;
			if (isDupCountLN) {
				parentDIN = (DIN) bin.fetchTarget(index);
				parentDIN.latch(Cleaner.UPDATE_GENERATION);
				ChildReference dclRef = parentDIN.getDupCountLNRef();
				treeLsn = dclRef.getLsn();
			} else {
				treeLsn = bin.getLsn(index);
			}

			/* Process this LN that was found in the tree. */
			processedHere = false;
			processFoundLN(info, logLsn, treeLsn, bin, index, parentDIN);
			completed = true;

			/*
			 * For all other non-deleted LNs in this BIN, lookup their LSN in
			 * the LN queue and process any matches.
			 */
		Label133: ;

			return;
		} finally {
			Label135:;
			if (processedHere) {
				cleaner.trace(cleaner.detailedTraceLevel, Cleaner.CLEAN_LN, ln,
						logLsn, completed, obsolete, false /* migrated */);
			}
		}
	}






 

 /** 
  * Processes the first LN in the look ahead cache and removes it from the cache. While the BIN is latched, look through the BIN for other LNs in the cache; if any match, process them to avoid a tree search later.
  * @param info
  * @param offset
  */
 private void processLN(Long fileNum, TreeLocation location, Long offset, LNInfo info, Object lookAheadCachep,
  Map dbCache) throws DatabaseException {


        /* Get the first LN from the queue. */

				Label132: ;
        LN ln = info.getLN();
        byte[] key = info.getKey();
        byte[] dupKey = info.getDupKey();

        long logLsn = DbLsn.makeLsn
            (fileNum.longValue(), offset.longValue());

        DatabaseImpl db = env.getDbMapTree().getDb
            (info.getDbId(), cleaner.lockTimeout, dbCache);

        /* Status variables are used to generate debug tracing info. */
        boolean processedHere = true; // The LN was cleaned here.
        boolean obsolete = false;     // The LN is no longer in use.
        boolean completed = false;    // This method completed.

        BIN bin = null;
        DIN parentDIN = null;      // for DupCountLNs
        try {

            /* 
             * If the DB is gone, this LN is obsolete.  If delete cleanup is in
             * progress, put the DB into the DB pending set; this LN will be
             * declared deleted after the delete cleanup is finished.
             */
						boolean ifFlag = (db == null);
						Label157: ;
            if ( ifFlag ) {
                Label158: ;

                Label148: ;

                obsolete = true;
                completed = true;
                return;
            }

            Tree tree = db.getTree();
            assert tree != null;

            /*
	     * Search down to the bottom most level for the parent of this LN.
	     */
            boolean parentFound = tree.getParentBINForChildLN
                (location, key, dupKey, ln,
                 false,  // splitsAllowed
                 true,   // findDeletedEntries
                 false,  // searchDupTree
                 Cleaner.UPDATE_GENERATION);
            bin = location.bin;
            int index = location.index;

            if (!parentFound) {
                Label149: ;
		obsolete = true;
                completed = true;
		return;
            }

	    /*
	     * Now we're at the parent for this LN, whether BIN, DBIN or DIN.
	     * If knownDeleted, LN is deleted and can be purged.
	     */
	    if (bin.isEntryKnownDeleted(index)) {
		Label150: ;
		obsolete = true;
		completed = true;
                return;
	    }

            /*
             * Determine whether the parent is the current BIN, or in the case
             * of a DupCountLN, a DIN.  Get the tree LSN in either case.
             */
            boolean isDupCountLN = ln.containsDuplicates();
            long treeLsn;
	    if (isDupCountLN) {
		parentDIN = (DIN) bin.fetchTarget(index);
		parentDIN.latch(Cleaner.UPDATE_GENERATION);
                ChildReference dclRef = parentDIN.getDupCountLNRef();
                treeLsn = dclRef.getLsn();
	    } else {
                treeLsn = bin.getLsn(index);
	    }

            /* Process this LN that was found in the tree. */
            processedHere = false;
            processFoundLN(info, logLsn, treeLsn, bin, index, parentDIN);
            completed = true;

            /*
             * For all other non-deleted LNs in this BIN, lookup their LSN
             * in the LN queue and process any matches.
             */
						Label133: ;
     

            return;
        } finally {
            if (parentDIN != null) {
                parentDIN.releaseLatchIfOwner();
            }

            if (bin != null) {
                bin.releaseLatchIfOwner();
            }

            Label126: ;

        }
    }

 /** 
  * Processes an LN that was found in the tree. Lock the LN's node ID and then set the entry's MIGRATE flag if the LSN of the LN log entry is the active LSN in the tree.
  * @param infoidentifies the LN log entry.
  * @param logLsnis the LSN of the log entry.
  * @param treeLsnis the LSN found in the tree.
  * @param binis the BIN found in the tree; is latched on method entry andexit.
  * @param indexis the BIN index found in the tree.
  * @param parentDINis non-null for a DupCountLN only; if non-null, is latched onmethod entry and exit.
  */
 private void processFoundLN(LNInfo info, long logLsn, long treeLsn, BIN bin, int index, DIN parentDIN)
 throws DatabaseException {
  LN ln = info.getLN();
  byte[] key = info.getKey();
  byte[] dupKey = info.getDupKey();
  DatabaseImpl db = bin.getDatabase();
  boolean isDupCountLN = parentDIN != null;
  boolean obsolete = false;
  boolean migrated = false;
  boolean lockDenied = false;
  boolean completed = false;
  long nodeId = ln.getNodeId();
  BasicLocker locker = null;
  try {
   Tree tree = db.getTree();
   assert tree != null;
   if (treeLsn != logLsn) {
    locker = new BasicLocker(env);
    LockResult lockRet = locker.nonBlockingLock(nodeId, LockType.READ, db);
    if (lockRet.getLockGrant() == LockGrantType.DENIED) {
     Label142:   ; //this.hook142();
      lockDenied = true;
    }
    else {
     Label143:   ; //this.hook143();
      obsolete = true;
    }
   }
   if (!obsolete && !lockDenied) {
    if (isDupCountLN) {
     ChildReference dclRef = parentDIN.getDupCountLNRef();
     dclRef.setMigrate(true);
     parentDIN.setDirty(true);
     if (treeLsn == logLsn && dclRef.getTarget() == null) {
      ln.postFetchInit(db, logLsn);
      parentDIN.updateDupCountLN(ln);
     }
    } else {
     bin.setMigrate(index, true);
     bin.setDirty(true);
     if (treeLsn == logLsn && bin.getTarget(index) == null) {
      ln.postFetchInit(db, logLsn);
      bin.updateEntry(index, ln);
     }
     if (PROHIBIT_DELTAS_WHEN_FETCHING && bin.getGeneration() == 0) {
      bin.setProhibitNextDelta();
     }
     bin.setGeneration();
    }
    Label144:   ; //this.hook144();
     migrated = true;
   }
   completed = true;
  } finally {
   if (locker != null) {
    locker.operationEnd();
   }
   if (completed && lockDenied) {
    fileSelector.addPendingLN(ln, db.getId(), key, dupKey);
   }
   Label124:   ; ;//this.hook124(logLsn, ln, obsolete, migrated, completed);
  }
 }

 /** 
  * If an IN is still in use in the in-memory tree, dirty it. The checkpoint invoked at the end of the cleaning run will end up rewriting it.
  */
 private void processIN(IN inClone, DatabaseImpl db, long lsn) throws DatabaseException {
    boolean obsolete = false;
    boolean dirtied = false;
    boolean completed = false; 
 try {
  
   //this.hook125(inClone, db, lsn, obsolete, dirtied, completed);
   Label125:;
    boolean b = db == null;
   //b = this.hook159(db, b);
   Label159:   ;
    if (b) {
     //this.hook160(db);
     Label160:   ; 
     Label151:   ; //this.hook151();
      obsolete = true;
     completed = true;
     return; //throw new ReturnVoid();
    }
   Tree tree = db.getTree();
   assert tree != null;
   IN inInTree = findINInTree(tree, db, inClone, lsn);
   if (inInTree == null) {
    Label152:   ; //this.hook152();
     obsolete = true;
   }
   else {
    Label153:   ; //this.hook153();
     inInTree.setDirty(true);
    inInTree.setProhibitNextDelta();
    Label136:   ; //this.hook136(inInTree);
     dirtied = true;
   }
   completed = true;
   //End of hook125
  } 
  finally {
    Label125_1: ; //;
  }


 }


	private boolean processFile(Long fileNum) throws DatabaseException,
			IOException {

		/* Get the current obsolete offsets for this file. */
		PackedOffsets obsoleteOffsets = new PackedOffsets();
		TrackedFileSummary tfs = profile.getObsoleteDetail(fileNum,
				obsoleteOffsets, true /* logUpdate */);
		PackedOffsets.Iterator obsoleteIter = obsoleteOffsets.iterator();
		long nextObsolete = -1;

		/* Keep in local variables because they are mutable properties. */
		final int readBufferSize = cleaner.readBufferSize;
		Label128: ;

		/*
		 * Add the overhead of this method to the budget. Two read buffers are
		 * allocated by the file reader. The log size of the offsets happens to
		 * be the same as the memory overhead.
		 */
		Label161: ;

		/* Evict after updating the budget. */
		Label116: ;

		/*
		 * We keep a look ahead cache of non-obsolete LNs. When we lookup a BIN
		 * in processLN, we also process any other LNs in that BIN that are in
		 * the cache. This can reduce the number of tree lookups.
		 */
		Label127: ;

		/*
		 * For obsolete entries we must check for pending deleted DBs. To avoid
		 * the overhead of DbTree.getDb on every entry we keep a set of all DB
		 * IDs encountered and do the check once per DB at the end.
		 */
		Set checkPendingDbSet = new HashSet();

		/* Use local caching to reduce DbTree.getDb overhead. */
		Map dbCache = new HashMap();

		try {
			/* Create the file reader. */
			CleanerFileReader reader = new CleanerFileReader(env,
					readBufferSize, DbLsn.NULL_LSN, fileNum);
			/* Validate all entries before ever deleting a file. */
			Label137: ;

			DbTree dbMapTree = env.getDbMapTree();
			TreeLocation location = new TreeLocation();

			int nProcessedLNs = 0;
			while (reader.readNextEntry()) {
				Label146: ;
				long lsn = reader.getLastLsn();
				long fileOffset = DbLsn.getFileOffset(lsn);
				boolean isLN = reader.isLN();
				boolean isIN = reader.isIN();
				boolean isRoot = reader.isRoot();
				boolean isObsolete = false;

				/* Stop if the daemon is shut down. */
				if (env.isClosing()) {
					return false;
				}

				/* Check for a known obsolete node. */
				while (nextObsolete < fileOffset && obsoleteIter.hasNext()) {
					nextObsolete = obsoleteIter.next();
				}
				if (nextObsolete == fileOffset) {
					isObsolete = true;
				}

				/* Check for the entry type next because it is very cheap. */
				if (!isObsolete && !isLN && !isIN && !isRoot) {
					/* Consider all entries we do not process as obsolete. */
					isObsolete = true;
				}

				/* Check for a deleted LN next because it is very cheap. */
				if (!isObsolete && isLN && reader.getLN().isDeleted()) {
					/* Deleted LNs are always obsolete. */
					isObsolete = true;
				}

				/* Check the current tracker last, as it is more expensive. */
				if (!isObsolete && tfs != null
						&& tfs.containsObsoleteOffset(fileOffset)) {
					isObsolete = true;
				}

				/* Skip known obsolete nodes. */
				if (isObsolete) {
					/* Count obsolete stats. */
			Label147: ;
					/* Must update the pending DB set for obsolete entries. */
					Label156: ;
					continue;
				}

				/* Evict before processing each entry. */
				Label119: ;

				/* The entry is not known to be obsolete -- process it now. */
				if (isLN) {

					LN targetLN = reader.getLN();
					DatabaseId dbId = reader.getDatabaseId();
					byte[] key = reader.getKey();
					byte[] dupKey = reader.getDupTreeKey();

					Long aLsn = new Long(DbLsn.getFileOffset(lsn));
					LNInfo aLninfo = new LNInfo(targetLN, dbId, key, dupKey);

          Label130: ;

    

					/*
					 * Process pending LNs before proceeding in order to prevent
					 * the pending list from growing too large.
					 */
					nProcessedLNs += 1;
					if (nProcessedLNs % PROCESS_PENDING_EVERY_N_LNS == 0) {
						cleaner.processPending();
					}

				} else if (isIN) {

					IN targetIN = reader.getIN();
					DatabaseId dbId = reader.getDatabaseId();
					DatabaseImpl db = dbMapTree.getDb(dbId,
							cleaner.lockTimeout, dbCache);
					targetIN.setDatabase(db);

					processIN(targetIN, db, lsn);

				} else if (isRoot) {

					env.rewriteMapTreeRoot(lsn);
				} else {
					assert false;
				}
			}

			/* Process remaining queued LNs. */
		Label129: ;

		Label155: ;

			/* Update reader stats. */
			 Label145: ;

		} finally {
			/* Subtract the overhead of this method from the budget. */
			Label162: ;

			/* Allow flushing of TFS when cleaning is complete. */
			if (tfs != null) {
				tfs.setAllowFlush(true);
			}
		}

		return true;
	}

 /** 
  * Given a clone of an IN that has been taken out of the log, try to find it in the tree and verify that it is the current one in the log. Returns the node in the tree if it is found and it is current re: LSN's. Otherwise returns null if the clone is not found in the tree or it's not the latest version. Caller is responsible for unlatching the returned IN.
  */
  private IN findINInTree(Tree tree, DatabaseImpl db, IN inClone, long lsn) throws DatabaseException {
    SearchResult result = null;
    try {
      if (inClone.isDbRoot()) {
        IN rootIN = isRoot(tree, db, inClone, lsn);
        if (rootIN == null) {
        return null;
        } else {
        return rootIN;
        }
      }
   inClone.latch(Cleaner.UPDATE_GENERATION);
   Label134:   ; //this.hook134(tree, db, inClone, lsn, result);
    result = tree.getParentINForChildIN(inClone, true, Cleaner.UPDATE_GENERATION, inClone.getLevel(), null);
   if (!result.exactParentFound) {
     return null;
   }
   int compareVal = DbLsn.compareTo(result.parent.getLsn(result.index), lsn);
   if (compareVal > 0) {
     return null;
   } else {
    IN in ;
    if (compareVal == 0) {
     in = (IN) result.parent.getTarget(result.index);
     if ( in == null) {
      in = inClone; in .postFetchInit(db, lsn);
      result.parent.updateEntry(result.index, in );
     }
    } else {
     in = (IN) result.parent.fetchTarget(result.index);
    } in .latch(Cleaner.UPDATE_GENERATION);
        return in ;
   }
  } 
 finally {
    Label134_1: ;
      }
 }

 /** 
  * Check if the cloned IN is the same node as the root in tree. Return the real root if it is, null otherwise. If non-null is returned, the returned IN (the root) is latched -- caller is responsible for unlatching it.
  */
 private IN isRoot(Tree tree, DatabaseImpl db, IN inClone, long lsn) throws DatabaseException {
  RootDoWork rdw = new RootDoWork(db, inClone, lsn);
  return tree.withRootLatchedShared(rdw);
 }

 /** 
  * XXX: Was this intended to override Thread.toString()? If so it no longer does, because we separated Thread from DaemonThread.
  */
 public String toString() {
  StringBuffer sb = new StringBuffer();
  sb.append("<Cleaner name=\"").append(name).append("\"/>");
  return sb.toString();
 }

}
